import valueIfValidHexDigit from "./utils"

export type Position { line: Int, col: Int }

export type Token {
  position: Position
  kind: TokenKind
}

export enum TokenKind {
  // Literals
  Int(value: Int)
  Float(value: Float)
  Bool(value: Bool)
  Char(ch: Int)
  String(value: String)
  StringInterpolation(chunks: StringInterpolationChunk[])

  // Identifiers/keywords
  Ident(name: String)
  If
  Else
  Val
  Var
  Func
  Self
  While
  Break
  Continue
  For
  In
  Match
  Type
  Enum
  Return(subsequentNewline: Bool)
  Readonly
  Import
  Export
  From
  As
  Try
  None_

  // Symbols
  Plus
  PlusEq
  Minus
  MinusEq
  Star
  StarEq
  StarStar
  Slash
  SlashEq
  Percent
  PercentEq
  LT
  LTE
  GT
  GTE
  Bang
  Neq
  Eq
  EqEq
  Arrow
  And
  AndEq
  Or
  OrEq
  Dot
  Caret
  LParen(preceedingNewline: Bool)
  RParen
  LBrack(preceedingNewline: Bool)
  RBrack
  LBrace
  RBrace
  HashBrace
  Pipe
  Comma
  Colon
  Question
  Elvis
  ElvisEq
  QuestionDot
  At

  func repr(self): String = match self {
    TokenKind.Int => "int"
    TokenKind.Float => "float"
    TokenKind.Bool(value) => value.toString()
    TokenKind.String => "string"
    TokenKind.StringInterpolation => "string"
    TokenKind.Char => "char"
    TokenKind.Ident(name) => if name == "_" { "_" } else "identifier"
    TokenKind.If => "if"
    TokenKind.Else => "else"
    TokenKind.Val => "val"
    TokenKind.Var => "var"
    TokenKind.Func => "func"
    TokenKind.Self => "self"
    TokenKind.While => "while"
    TokenKind.Break => "break"
    TokenKind.Continue => "continue"
    TokenKind.For => "for"
    TokenKind.In => "in"
    TokenKind.Match => "match"
    TokenKind.Type => "type"
    TokenKind.Enum => "enum"
    TokenKind.Return => "return"
    TokenKind.Readonly => "readonly"
    TokenKind.Import => "import"
    TokenKind.Export => "export"
    TokenKind.From => "from"
    TokenKind.As => "as"
    TokenKind.Try => "try"
    TokenKind.None_ => "None"
    TokenKind.Plus => "+"
    TokenKind.PlusEq => "+="
    TokenKind.Minus => "-"
    TokenKind.MinusEq => "-="
    TokenKind.Star => "*"
    TokenKind.StarEq => "*="
    TokenKind.StarStar => "**"
    TokenKind.Slash => "/"
    TokenKind.SlashEq => "/="
    TokenKind.Percent => "%"
    TokenKind.PercentEq => "%="
    TokenKind.LT => "<"
    TokenKind.LTE => "<="
    TokenKind.GT => ">"
    TokenKind.GTE => ">="
    TokenKind.Bang => "!"
    TokenKind.Neq => "!="
    TokenKind.Eq => "="
    TokenKind.EqEq => "=="
    TokenKind.Arrow => "=>"
    TokenKind.And => "&&"
    TokenKind.AndEq => "&&="
    TokenKind.Or => "||"
    TokenKind.OrEq => "||="
    TokenKind.Dot => "."
    TokenKind.Caret => "^"
    TokenKind.LParen => "("
    TokenKind.RParen => ")"
    TokenKind.LBrack => "["
    TokenKind.RBrack => "]"
    TokenKind.LBrace => "{"
    TokenKind.RBrace => "}"
    TokenKind.HashBrace => "#{"
    TokenKind.Pipe => "|"
    TokenKind.Comma => ","
    TokenKind.Colon => ":"
    TokenKind.Question => "?"
    TokenKind.Elvis => "?:"
    TokenKind.ElvisEq => "?:="
    TokenKind.QuestionDot => "?."
    TokenKind.At => "@"
  }
}

export enum StringInterpolationChunk {
  String(position: Position, value: String)
  Interpolation(tokens: Token[])
}

export enum LexerErrorKind {
  UnexpectedChar(char: String)
  UnterminatedCharLiteral
  UnterminatedString(start: Position)
  UnsupportedEscapeSequence(seq: String, isUnicode: Bool)
  UnexpectedEof
}

export type LexerError {
  position: Position
  kind: LexerErrorKind

  func getMessage(self, filePath: String, contents: String): String {
    val lines = ["Error at $filePath:${self.position.line}:${self.position.col}"]

    match self.kind {
      LexerErrorKind.UnexpectedChar(char) => {
        lines.push("Unexpected character '$char':")
        lines.push(self._getCursorLine(self.position, contents))
      }
      LexerErrorKind.UnterminatedCharLiteral => {
        lines.push("Unterminated character literal:")
        lines.push(self._getCursorLine(self.position, contents))
      }
      LexerErrorKind.UnterminatedString(start) => {
        lines.push("Unterminated string:")
        lines.push("  String begins at (${start.line}:${start.col})")
        lines.push(self._getCursorLine(start, contents))
        lines.push("  String is terminated at (${self.position.line}:${self.position.col})")
        lines.push(self._getCursorLine(self.position, contents))
      }
      LexerErrorKind.UnsupportedEscapeSequence(seq, isUnicode) => {
        lines.push("Unsupported escape sequence:")
        lines.push(self._getCursorLine(self.position, contents, seq.length))
        if isUnicode {
          lines.push("Unicode escape sequences must be \\u followed by 4 hexadecimal characters (between 0000 and 7FFF)")
        }
      }
      LexerErrorKind.UnexpectedEof => {
        lines.push("Unexpected end of file:")
        lines.push(self._getCursorLine(self.position, contents))
      }
    }

    lines.join("\n")
  }

  func _getCursorLine(self, position: Position, contents: String, cursorLength = 1): String {
    if contents.lines()[position.line - 1] |line| {
      val len = position.col - 1 + cursorLength
      val cursor = Array.fill(len, " ")
      for i in range(len - cursorLength, len) {
        cursor[i] = "^"
      }
      "  |  $line\n     ${cursor.join()}"
    } else {
      // "unreachable"
      unreachable()
    }
  }
}

export type Lexer {
  _input: String
  _cursor: Int = 0
  _line: Int = 1
  _col: Int = 1

  func tokenize(contents: String): Result<Token[], LexerError> {
    val tokens: Token[] = []

    val lexer = Lexer(_input: contents)
    var nextToken = try lexer.nextToken()
    while nextToken |tok| {
      tokens.push(tok)

      nextToken = try lexer.nextToken()
    }

    Ok(tokens)
  }

  func nextToken(self): Result<Token?, LexerError> {
    val sawNewline = self._skipWhitespace()

    if self._cursor >= self._input.length return Ok(None)
    val ch = self._input[self._cursor]
    val peek = self._input[self._cursor + 1]

    val position = self._curPos()

    val token = if ch.isDigit() {
      try self._tokenizeInteger(startPos: position)
    } else if ch == "\"" {
      try self._tokenizeString()
    } else if ch == "'" {
      try self._tokenizeChar()
    } else if ch.isAlpha() || ch == "_" {
      self._tokenizeIdentifier(startPos: position)
    } else if ch == "/" && (peek == "/" || peek == "*") {
      if self._skipComment() |error| return Err(error)
      return self.nextToken()
    } else {
      try self._tokenizeSymbol(startPos: position, sawPreceedingNewline: sawNewline)
    }

    Ok(Some(token))
  }

  func _curPos(self): Position = Position(line: self._line, col: self._col)

  func _advance(self, by = 1) {
    self._cursor += by
    self._col += by
  }

  func _skipWhitespace(self): Bool {
    if self._cursor >= self._input.length return false

    var sawNewline = false
    var ch = self._input[self._cursor]
    while ch == " " || ch == "\n" {
      self._advance()
      if ch == "\n" {
        self._line += 1
        self._col = 1
        sawNewline = true
      }
      ch = self._input[self._cursor]
    }

    sawNewline
  }

  func _skipComment(self): LexerError? {
    if self._cursor >= self._input.length return None

    val ch = self._input[self._cursor]
    val peek = self._input[self._cursor + 1]
    if ch == "/" && peek == "/" {
      while self._cursor < self._input.length && self._input[self._cursor] != "\n" {
        self._advance()
      }
    } else if ch == "/" && peek == "*" {
      self._advance(by: 2) // consume '/' and '*'
      var open = true
      while self._cursor < self._input.length {
        if self._input[self._cursor] == "*" && self._input[self._cursor + 1] == "/" {
          self._advance(by : 2) // consume '*' and '/'
          open = false
          break
        }
        self._advance()
        self._skipWhitespace()
      }

      if open {
        self._advance()
        return Some(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof))
      }
    }

    None
  }

  func _multiCharToken(self, default: TokenKind, cases: (String, TokenKind)[]): TokenKind {
    val peekCursor = self._cursor + 1
    for (str, tokenKind) in cases {
      if self._input[peekCursor:(peekCursor + str.length)] == str {
        self._advance(by: str.length)
        return tokenKind
      }
    }

    default
  }

  func _tokenizeInteger(self, startPos: Position): Result<Token, LexerError> {
    val ch = self._input[self._cursor]
    if ch == "0" {
      if self._input[self._cursor + 1] == "x" {
        self._advance() // consume 'x'
        self._advance() // move to next

        var isFirstChar = true
        var num = 0
        while self._cursor < self._input.length {
          val ch = self._input._buffer.offset(self._cursor).load().asInt()
          val v = if valueIfValidHexDigit(ch) |v| v else break

          num = (num << 4) + v
          isFirstChar = false

          self._advance()
        }

        if isFirstChar {
          val kind = if self._cursor < self._input.length {
            val char = self._input[self._cursor]
            LexerErrorKind.UnexpectedChar(char)
          } else {
            LexerErrorKind.UnexpectedEof
          }

          return Err(LexerError(position: self._curPos(), kind: kind))
        }

        return Ok(Token(position: startPos, kind: TokenKind.Int(num)))
      } else if self._input[self._cursor + 1] == "b" {
        self._advance() // consume 'b'
        self._advance() // move to next

        var isFirstChar = true
        var num = 0
        while self._cursor < self._input.length {
          val ch = self._input._buffer.offset(self._cursor).load().asInt()
          val v = if ch == 48 || ch == 49 { ch - 48 } else break

          num = (num << 1) + v
          isFirstChar = false

          self._advance()
        }

        if isFirstChar {
          val kind = if self._cursor < self._input.length {
            val char = self._input[self._cursor]
            LexerErrorKind.UnexpectedChar(char)
          } else {
            LexerErrorKind.UnexpectedEof
          }

          return Err(LexerError(position: self._curPos(), kind: kind))
        }

        return Ok(Token(position: startPos, kind: TokenKind.Int(num)))
      } else if self._input[self._cursor + 1].isDigit() {
        self._advance()
        val char = self._input[self._cursor]
        return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(char)))
      }
    }

    // ord('0') = 48
    var num = ch._buffer.load().asInt() - 48
    self._advance()
    while self._input[self._cursor].isDigit() {
      num *= 10
      num += self._input._buffer.offset(self._cursor).load().asInt() - 48
      self._advance()
    }

    if self._input[self._cursor] == "." && self._input[self._cursor + 1].isDigit() {
      return self._tokenizeFloat(startPos: startPos, wholeNumber: num)
    }

    Ok(Token(position: startPos, kind: TokenKind.Int(num)))
  }

  func _tokenizeFloat(self, startPos: Position, wholeNumber: Int): Result<Token, LexerError> {
    self._advance() // consume '.'

    var pow = 1
    var num = self._input._buffer.offset(self._cursor).load().asInt() - 48
    self._advance()
    while self._input[self._cursor].isDigit() {
      num *= 10
      num += self._input._buffer.offset(self._cursor).load().asInt() - 48
      self._advance()
      pow += 1
    }

    if self._input[self._cursor] == "." && self._input[self._cursor + 1].isDigit() {
      val char = self._input[self._cursor]
      return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(char)))
    }

    val float = wholeNumber + (num / (10 ** pow))
    Ok(Token(position: startPos, kind: TokenKind.Float(float)))
  }

  func _tokenizeChar(self): Result<Token, LexerError> {
    var startPos = self._curPos()
    self._advance() // consume "'"

    var ch = self._input[self._cursor]
    if ch == "'" return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(ch)))
    val intVal = if ch == "\\" {
      val pos = self._curPos()
      self._advance() // consume '\'
      if self._cursor >= self._input.length return Err(LexerError(position: pos, kind: LexerErrorKind.UnexpectedEof))
      ch = self._input[self._cursor]

      match ch {
        "0" => 0
        "n" => 10
        "\\" => 92
        "r" => 13
        "t" => 9
        "'" => 39
        "u" => {
          val ch = try self._parseUnicodeEscape(pos)
          ch.asInt()
        }
        _ => return Err(LexerError(position: pos, kind: LexerErrorKind.UnsupportedEscapeSequence(seq: "\\$ch", isUnicode: false)))
      }
    } else {
      // TODO: once characters are supported, there should be no need for low-level byte manipulation like this
      ch._buffer.offset(0).load().asInt()
    }

    self._advance()

    ch = self._input[self._cursor]
    if self._cursor >= self._input.length || ch != "'" {
      return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnterminatedCharLiteral))
    }
    self._advance() // consume "'"

    Ok(Token(position: startPos, kind: TokenKind.Char(intVal)))
  }

  func _tokenizeString(self): Result<Token, LexerError> {
    var startPos = self._curPos()
    val origStartPos = startPos
    self._advance() // consume '"'

    var chars: String[] = []
    var interpolationChunks: StringInterpolationChunk[]? = None
    var start = self._cursor
    var closed = false
    var seenEscape = false
    while self._cursor < self._input.length {
      val ch = self._input[self._cursor]
      if ch == "\n" {
        return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnterminatedString(startPos)))
      } else if ch == "\\" {
        val startCursor = self._cursor
        val pos = self._curPos()
        self._advance() // consume '\'

        val ch = self._input[self._cursor]
        val escapedCh = match ch {
          "n" => "\n"
          "\\" => "\\"
          "r" => "\r"
          "t" => "\t"
          // "\'" => "\'"
          "\"" => "\""
          "$" => "$"
          "u" => {
            val ch = try self._parseUnicodeEscape(pos)
            ch.toString()
          }
          _ => return Err(LexerError(position: pos, kind: LexerErrorKind.UnsupportedEscapeSequence(seq: "\\$ch", isUnicode: false)))
        }

        if !seenEscape {
          seenEscape = true
          chars = self._input[start:startCursor].split()
        }
        chars.push(escapedCh)
      } else if ch == "$" && (self._input[self._cursor + 1] == "{" || self._input[self._cursor + 1].isAlpha()) {
        val str = if seenEscape {
          seenEscape = false
          chars.join()
        } else self._input[start:self._cursor]
        self._advance() // consume '$'
        if self._input[self._cursor] == "{" {
          val initialChunk = StringInterpolationChunk.String(position: startPos, value: str)
          try self.nextToken()

          val interpolatedTokens: Token[] = []
          var curlyCount = 1
          while curlyCount != 0 {
            val nextToken = try self.nextToken()
            if nextToken |tok| {
              if tok.kind == TokenKind.LBrace {
                curlyCount += 1
              } else if tok.kind == TokenKind.RBrace {
                curlyCount -= 1
                if curlyCount == 0 {
                  break // don't push '}' into interpolatedTokens
                }
              }
              interpolatedTokens.push(tok)
            } else {
              return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof))
            }
          }

          if interpolationChunks |existingChunks| {
            existingChunks.push(initialChunk)
            existingChunks.push(StringInterpolationChunk.Interpolation(interpolatedTokens))
          } else {
            interpolationChunks = Some([initialChunk, StringInterpolationChunk.Interpolation(interpolatedTokens)])
          }
          start = self._cursor
          startPos = self._curPos()
          continue
        } else if self._input[self._cursor].isAlpha() {
          val position = self._curPos()
          val token = self._tokenizeIdentifier(position)
          val chunk = StringInterpolationChunk.Interpolation([token])

          if interpolationChunks |existingChunks| {
            existingChunks.push(StringInterpolationChunk.String(position: startPos, value: str))
            existingChunks.push(chunk)
          } else {
            interpolationChunks = Some([StringInterpolationChunk.String(position: startPos, value: str), chunk])
          }
          start = self._cursor
          startPos = self._curPos()
          continue
        } else {
          // should be unreachable
          unreachable()
        }
      } else if ch == "\"" {
        closed = true
        break
      } else {
        if seenEscape {
         chars.push(ch)
        }
      }

      self._advance()
    }

    if !closed {
      return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnterminatedString(origStartPos)))
    }

    val str = if seenEscape chars.join() else self._input[start:self._cursor]

    self._advance() // consume closing '"'

    if interpolationChunks |chunks| {
      chunks.push(StringInterpolationChunk.String(position: startPos, value: str))
      Ok(Token(position: origStartPos, kind: TokenKind.StringInterpolation(chunks)))
    } else {
      Ok(Token(position: startPos, kind: TokenKind.String(str)))
    }
  }

  func _parseUnicodeEscape(self, startPos: Position): Result<Char, LexerError> {
    self._advance() // consume 'u'

    var value = 0
    for i in range(0, 4) {
      if self._cursor + i >= self._input.length {
        val escSeq = "\\u${self._input[self._cursor:self._cursor + i]}"
        return Err(LexerError(position: startPos, kind: LexerErrorKind.UnsupportedEscapeSequence(seq: escSeq, isUnicode: true)))
      }
      val ch = self._input._buffer.offset(self._cursor + i).load().asInt()
      val v = if valueIfValidHexDigit(ch) |v| v else {
        val escSeq = "\\u${self._input[self._cursor:self._cursor + i]}"
        return Err(LexerError(position: startPos, kind: LexerErrorKind.UnsupportedEscapeSequence(seq: escSeq, isUnicode: true)))
      }
      value = (value << 4) + v
    }
    self._advance()
    self._advance()
    self._advance()

    Ok(Char.fromInt(value))
  }

  func _tokenizeIdentifier(self, startPos: Position): Token {
    val identStart = self._cursor
    var ch = self._input[self._cursor]

    while ch.isAlphanumeric() || ch == "_" {
      self._advance()
      ch = self._input[self._cursor]
    }

    val ident = self._input[identStart:self._cursor]
    val tokenKind = match ident {
      "true" => TokenKind.Bool(true)
      "false" => TokenKind.Bool(false)
      "if" => TokenKind.If
      "else" => TokenKind.Else
      "val" => TokenKind.Val
      "var" => TokenKind.Var
      "func" => TokenKind.Func
      "self" => TokenKind.Self
      "while" => TokenKind.While
      "break" => TokenKind.Break
      "continue" => TokenKind.Continue
      "for" => TokenKind.For
      "in" => TokenKind.In
      "match" => TokenKind.Match
      "type" => TokenKind.Type
      "enum" => TokenKind.Enum
      "return" => {
        val sawNewline = self._skipWhitespace()
        TokenKind.Return(sawNewline)
      }
      "readonly" => TokenKind.Readonly
      "import" => TokenKind.Import
      "export" => TokenKind.Export
      "from" => TokenKind.From
      "as" => TokenKind.As
      "try" => TokenKind.Try
      "None" => TokenKind.None_
      _ => TokenKind.Ident(ident)
    }
    Token(position: startPos, kind: tokenKind)
  }

  func _tokenizeSymbol(self, startPos: Position, sawPreceedingNewline: Bool): Result<Token, LexerError> {
    val ch = self._input[self._cursor]

    val tokenKind = match ch {
      "+" => self._multiCharToken(TokenKind.Plus, [("=", TokenKind.PlusEq)])
      "-" => self._multiCharToken(TokenKind.Minus, [("=", TokenKind.MinusEq)])
      "*" => self._multiCharToken(TokenKind.Star, [("=", TokenKind.StarEq), ("*", TokenKind.StarStar)])
      "/" => self._multiCharToken(TokenKind.Slash, [("=", TokenKind.SlashEq)])
      "%" => self._multiCharToken(TokenKind.Percent, [("=", TokenKind.PercentEq)])
      "<" => self._multiCharToken(TokenKind.LT, [("=", TokenKind.LTE)])
      ">" => self._multiCharToken(TokenKind.GT, [("=", TokenKind.GTE)])
      "!" => self._multiCharToken(TokenKind.Bang, [("=", TokenKind.Neq)])
      "=" => self._multiCharToken(TokenKind.Eq, [("=", TokenKind.EqEq), (">", TokenKind.Arrow)])
      "." => TokenKind.Dot
      "^" => TokenKind.Caret
      "(" => TokenKind.LParen(preceedingNewline: sawPreceedingNewline)
      ")" => TokenKind.RParen
      "[" => TokenKind.LBrack(preceedingNewline: sawPreceedingNewline)
      "]" => TokenKind.RBrack
      "{" => TokenKind.LBrace
      "}" => TokenKind.RBrace
      "&" => {
        self._advance() // consume first '&'
        if self._cursor >= self._input.length {
          return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof))
        } else if self._input[self._cursor] != "&" {
          val ch = self._input[self._cursor]
          return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(ch)))
        }

        // If the next character is '=' then advance over second '&'. Either way, the final character will
        // be consumed by the call to `self._advance()` at the end of this method
        if self._input[self._cursor + 1] == "=" {
          self._advance()
          TokenKind.AndEq
        } else {
          TokenKind.And
        }
      }
      "|" => self._multiCharToken(TokenKind.Pipe, [("|=", TokenKind.OrEq), ("|", TokenKind.Or)])
      "," => TokenKind.Comma
      ":" => TokenKind.Colon
      "?" => self._multiCharToken(TokenKind.Question, [(":=", TokenKind.ElvisEq), (":", TokenKind.Elvis), (".", TokenKind.QuestionDot)])
      "#" => {
        self._advance() // consume '#'
        if self._cursor >= self._input.length {
          return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof))
        } else if self._input[self._cursor] != "{" {
          val ch = self._input[self._cursor]
          return Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(ch)))
        }

        TokenKind.HashBrace
      }
      "@" => TokenKind.At
      _ => return Err(LexerError(position: startPos, kind: LexerErrorKind.UnexpectedChar(ch)))
    }

    self._advance()

    Ok(Token(position: startPos, kind: tokenKind))
  }
}
