export type Position { line: Int, col: Int }

export type Token {
  position: Position
  kind: TokenKind
  intValue: Int = 0
  strValue: String = ""
}

// TODO: When tagged union enums are fixed w.r.t. garbage collection, switch back to this implementation
// export enum TokenKind {
//   Int(value: Int)
//   Ident(name: String)
//   Dot
// }
export enum TokenKind {
  Int,
  Ident,
  Dot
}

export type Lexer {
  _input: String
  _cursor: Int = 0
  _line: Int = 1
  _col: Int = 1

  func tokenize(contents: String): Token[] {
    val tokens: Token[] = []

    val lexer = Lexer(_input: contents)
    while lexer.nextToken() |tok| {
      tokens.push(tok)
    }
    
    tokens
  }

  func nextToken(self): Token? {
    if self._cursor >= self._input.length return None

    self._skipWhitespace()
    val ch = self._input[self._cursor]

    val position = self._curPos()

    if ch.isDigit() {
      self._tokenizeInteger(startPos: position)
    } else if ch == "." {
      self._advance()
      Token(position: position, kind: TokenKind.Dot)
    } else if ch.isAlpha() {
      self._tokenizeIdent(startPos: position)
    } else {
      // TODO: This is unreachable, but the rust implementation fails to convert the result of this if-expression to an Option
      // for some reason. This should be fixed separately
      None
    }
  }

  func _curPos(self): Position = Position(line: self._line, col: self._col)

  func _advance(self) {
    self._cursor += 1
    self._col += 1
  }

  func _skipWhitespace(self) {
    var ch = self._input[self._cursor]
    while ch == " " || ch == "\n" { 
      self._advance() 
      if ch == "\n" {
        self._line += 1
        self._col = 1
      }
      ch = self._input[self._cursor]
    } 
  }

  func _tokenizeInteger(self, startPos: Position): Token {
    val ch = self._input[self._cursor]
    if ch == "0" && self._input[self._cursor + 1] == "x" {
      self._advance() // consume 'x'
      self._advance() // move to next

      var num = 0
      var ch = self._input._buffer.offset(self._cursor).load().asInt()
      while self._cursor < self._input.length {
        val v = if 48 <= ch && ch <= 57 { // 0-9
          (ch - 48)
        } else if 65 <= ch && ch <= 70 { // A-F
          (ch - 65) + 10
        } else if 97 <= ch && ch <= 102 { // a-f
          (ch - 97) + 10
        } else {
          //println("not valid hex char:", self._input[self._cursor])
          break
        }

        num = (num << 4) + v

        self._advance()
        ch = self._input._buffer.offset(self._cursor).load().asInt()
      }

      return Token(position: startPos, kind: TokenKind.Int, intValue: num)
    }

    // ord('0') = 48
    var num = ch._buffer.load().asInt() - 48
    self._advance()
    while self._input[self._cursor].isDigit() {
      num *= 10
      num += self._input._buffer.offset(self._cursor).load().asInt() - 48
      self._advance()
    }

    Token(position: startPos, kind: TokenKind.Int, intValue: num)
  }

  func _tokenizeIdent(self, startPos: Position): Token {
    val identStart = self._cursor
    var ch = self._input[self._cursor]

    while ch.isAlpha() || ch.isDigit() || ch == "_" { 
      self._advance()
      ch = self._input[self._cursor]
    }

    val ident = self._input[identStart:self._cursor]
    Token(position: startPos, kind: TokenKind.Ident, strValue: ident)
  }
}
