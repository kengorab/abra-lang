import valueIfValidHexDigit from "./utils"

export type Position { line: Int, col: Int }

export type Token {
  position: Position
  kind: TokenKind
}

export enum TokenKind {
  // Literals
  Int(value: Int)
  Float(value: Float)
  Bool(value: Bool)
  String(value: String)
  StringInterpolation(chunks: Token[])

  // Identifiers/keywords
  Ident(name: String)
  If
  Else
  Val
  Var
  Func
  Self
  While
  Break
  Continue
  For
  In
  Match
  Type
  Enum
  Return
  Readonly
  Import
  Export
  From
  As
  Try
  None_

  // Symbols
  Plus
  PlusEq
  Minus
  MinusEq
  Star
  StarEq
  StarStar
  Slash
  SlashEq
  Percent
  PercentEq
  LT
  LTE
  GT
  GTE
  Bang
  Neq
  Eq
  EqEq
  Arrow
  And
  AndEq
  Or
  OrEq
  Dot
  Caret
  LParen(preceedingNewline: Bool)
  RParen
  LBrack(preceedingNewline: Bool)
  RBrack
  LBrace
  RBrace
  HashBrace
  Pipe
  Comma
  Colon
  Question
  Elvis
  ElvisEq
  QuestionDot
  At

  func repr(self): String = match self {
    TokenKind.Int => "int"
    TokenKind.Float => "float"
    TokenKind.Bool(value) => value.toString()
    TokenKind.String => "string"
    TokenKind.StringInterpolation => "string"
    TokenKind.Ident => "identifier"
    TokenKind.If => "if"
    TokenKind.Else => "else"
    TokenKind.Val => "val"
    TokenKind.Var => "var"
    TokenKind.Func => "func"
    TokenKind.Self => "self"
    TokenKind.While => "while"
    TokenKind.Break => "break"
    TokenKind.Continue => "continue"
    TokenKind.For => "for"
    TokenKind.In => "in"
    TokenKind.Match => "match"
    TokenKind.Type => "type"
    TokenKind.Enum => "enum"
    TokenKind.Return => "return"
    TokenKind.Readonly => "readonly"
    TokenKind.Import => "import"
    TokenKind.Export => "export"
    TokenKind.From => "from"
    TokenKind.As => "as"
    TokenKind.Try => "try"
    TokenKind.None_ => "None"
    TokenKind.Plus => "+"
    TokenKind.PlusEq => "+="
    TokenKind.Minus => "-"
    TokenKind.MinusEq => "-="
    TokenKind.Star => "*"
    TokenKind.StarEq => "*="
    TokenKind.StarStar => "**"
    TokenKind.Slash => "/"
    TokenKind.SlashEq => "/="
    TokenKind.Percent => "%"
    TokenKind.PercentEq => "%="
    TokenKind.LT => "<"
    TokenKind.LTE => "<="
    TokenKind.GT => ">"
    TokenKind.GTE => ">="
    TokenKind.Bang => "!"
    TokenKind.Neq => "!="
    TokenKind.Eq => "="
    TokenKind.EqEq => "=="
    TokenKind.Arrow => "=>"
    TokenKind.And => "&&"
    TokenKind.AndEq => "&&="
    TokenKind.Or => "||"
    TokenKind.OrEq => "||="
    TokenKind.Dot => "."
    TokenKind.Caret => "^"
    TokenKind.LParen => "("
    TokenKind.RParen => ")"
    TokenKind.LBrack => "["
    TokenKind.RBrack => "]"
    TokenKind.LBrace => "{"
    TokenKind.RBrace => "}"
    TokenKind.HashBrace => "#{"
    TokenKind.Pipe => "|"
    TokenKind.Comma => ","
    TokenKind.Colon => ":"
    TokenKind.Question => "?"
    TokenKind.Elvis => "?:"
    TokenKind.ElvisEq => "?:="
    TokenKind.QuestionDot => "?."
    TokenKind.At => "@"
  }
}

export enum LexerErrorKind {
  UnexpectedChar(char: String)
  UnterminatedString(start: Position)
  UnsupportedEscapeSequence(seq: String, isUnicode: Bool)
  UnexpectedEof
}

export type LexerError {
  position: Position
  kind: LexerErrorKind

  func getMessage(self, filePath: String, contents: String): String {
    val lines = ["Error at $filePath:${self.position.line}:${self.position.col}"]

    match self.kind {
      LexerErrorKind.UnexpectedChar(char) => {
        lines.push("Unexpected character '$char':")
        lines.push(self._getCursorLine(self.position, contents))
      }
      LexerErrorKind.UnterminatedString(start) => {
        lines.push("Unterminated string:")
        lines.push("  String begins at (${start.line}:${start.col})")
        lines.push(self._getCursorLine(start, contents))
        lines.push("  String is terminated at (${self.position.line}:${self.position.col})")
        lines.push(self._getCursorLine(self.position, contents))
      }
      LexerErrorKind.UnsupportedEscapeSequence(seq, isUnicode) => {
        lines.push("Unsupported escape sequence:")
        lines.push(self._getCursorLine(self.position, contents, seq.length))
        if isUnicode {
          lines.push("Unicode escape sequences must be \\u followed by 4 hexadecimal characters (between 0000 and 7FFF)")
        }
      }
      LexerErrorKind.UnexpectedEof => {
        lines.push("Unexpected end of file:")
        lines.push(self._getCursorLine(self.position, contents))
      }
    }

    lines.join("\n")
  }

  func _getCursorLine(self, position: Position, contents: String, cursorLength = 1): String {
    if contents.lines()[position.line - 1] |line| {
      val len = position.col - 1 + cursorLength
      val cursor = Array.fill(len, " ")
      for i in range(len - cursorLength, len) {
        cursor[i] = "^"
      }
      "  |  $line\n     ${cursor.join()}"
    } else {
      "unreachable"
    }
  }
}

export type Lexer {
  _input: String
  _cursor: Int = 0
  _line: Int = 1
  _col: Int = 1

  func tokenize(contents: String): Result<Token[], LexerError> {
    val tokens: Token[] = []

    val lexer = Lexer(_input: contents)
    var nextToken = match lexer.nextToken() {
      Result.Ok(v) => v,
      Result.Err(e) => return Result.Err(error: e)
    }
    while nextToken |tok| {
      tokens.push(tok)

      nextToken = match lexer.nextToken() {
        Result.Ok(v) => v,
        Result.Err(e) => return Result.Err(error: e)
      }
    }

    Result.Ok(tokens)
  }

  func nextToken(self): Result<Token?, LexerError> {
    val sawNewline = self._skipWhitespace()

    if self._cursor >= self._input.length return Result.Ok(None)
    val ch = self._input[self._cursor]
    val peek = self._input[self._cursor + 1]

    val position = self._curPos()

    val token = if ch.isDigit() {
      val tok = match self._tokenizeInteger(startPos: position) {
        Result.Ok(v) => v
        Result.Err(e) => return Result.Err(error: e)
      }
      tok
    } else if ch == "\"" {
      val tok = match self._tokenizeString(startPos: position) {
        Result.Ok(v) => v
        Result.Err(e) => return Result.Err(error: e)
      }
      tok
    } else if ch.isAlpha() || ch == "_" {
      self._tokenizeIdentifier(startPos: position)
    } else if ch == "/" && (peek == "/" || peek == "*") {
      if self._skipComment() |error| return Result.Err(error)
      return self.nextToken()
    } else {
      val tok = match self._tokenizeSymbol(startPos: position, sawPreceedingNewline: sawNewline) {
        Result.Ok(v) => v
        Result.Err(e) => return Result.Err(error: e)
      }
      tok
    }

    Result.Ok(token)
  }

  func _curPos(self): Position = Position(line: self._line, col: self._col)

  func _advance(self, by = 1) {
    self._cursor += by
    self._col += by
  }

  func _skipWhitespace(self): Bool {
    if self._cursor >= self._input.length return false

    var sawNewline = false
    var ch = self._input[self._cursor]
    while ch == " " || ch == "\n" {
      self._advance()
      if ch == "\n" {
        self._line += 1
        self._col = 1
        sawNewline = true
      }
      ch = self._input[self._cursor]
    }

    sawNewline
  }

  func _skipComment(self): LexerError? {
    if self._cursor >= self._input.length return None

    val ch = self._input[self._cursor]
    val peek = self._input[self._cursor + 1]
    if ch == "/" && peek == "/" {
      while self._cursor < self._input.length && self._input[self._cursor] != "\n" {
        self._advance()
      }
    } else if ch == "/" && peek == "*" {
      self._advance(by: 2) // consume '/' and '*'
      var open = true
      while self._cursor < self._input.length {
        if self._input[self._cursor] == "*" && self._input[self._cursor + 1] == "/" {
          self._advance(by : 2) // consume '*' and '/'
          open = false
          break
        }
        self._advance()
        self._skipWhitespace()
      }

      if open {
        self._advance()
        return LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof)
      }
    }

    None
  }

  func _multiCharToken(self, default: TokenKind, cases: (String, TokenKind)[]): TokenKind {
    val peekCursor = self._cursor + 1
    for case in cases {
      if self._input[peekCursor:(peekCursor + case[0].length)] == case[0] {
        self._advance(by: case[0].length)
        return case[1]
      }
    }

    default
  }

  func _tokenizeInteger(self, startPos: Position): Result<Token, LexerError> {
    val ch = self._input[self._cursor]
    if ch == "0" {
      if self._input[self._cursor + 1] == "x" {
        self._advance() // consume 'x'
        self._advance() // move to next

        var isFirstChar = true
        var num = 0
        while self._cursor < self._input.length {
          val ch = self._input._buffer.offset(self._cursor).load().asInt()
          val v = if valueIfValidHexDigit(ch) |v| v else break

          num = (num << 4) + v
          isFirstChar = false

          self._advance()
        }

        if isFirstChar {
          val kind = if self._cursor < self._input.length {
            val char = self._input[self._cursor]
            LexerErrorKind.UnexpectedChar(char)
          } else {
            LexerErrorKind.UnexpectedEof
          }

          return Result.Err(LexerError(position: self._curPos(), kind: kind))
        }

        return Result.Ok(Token(position: startPos, kind: TokenKind.Int(num)))
      } else if self._input[self._cursor + 1] == "b" {
        self._advance() // consume 'b'
        self._advance() // move to next

        var isFirstChar = true
        var num = 0
        while self._cursor < self._input.length {
          val ch = self._input._buffer.offset(self._cursor).load().asInt()
          val v = if ch == 48 || ch == 49 { ch - 48 } else break

          num = (num << 1) + v
          isFirstChar = false

          self._advance()
        }

        if isFirstChar {
          val kind = if self._cursor < self._input.length {
            val char = self._input[self._cursor]
            LexerErrorKind.UnexpectedChar(char)
          } else {
            LexerErrorKind.UnexpectedEof
          }

          return Result.Err(LexerError(position: self._curPos(), kind: kind))
        }

        return Result.Ok(Token(position: startPos, kind: TokenKind.Int(num)))
      } else if self._input[self._cursor + 1].isDigit() {
        self._advance()
        val char = self._input[self._cursor]
        return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(char)))
      }
    }

    // ord('0') = 48
    var num = ch._buffer.load().asInt() - 48
    self._advance()
    while self._input[self._cursor].isDigit() {
      num *= 10
      num += self._input._buffer.offset(self._cursor).load().asInt() - 48
      self._advance()
    }

    if self._input[self._cursor] == "." && self._input[self._cursor + 1].isDigit() {
      return self._tokenizeFloat(startPos: startPos, wholeNumber: num)
    }

    Result.Ok(Token(position: startPos, kind: TokenKind.Int(num)))
  }

  func _tokenizeFloat(self, startPos: Position, wholeNumber: Int): Result<Token, LexerError> {
    self._advance() // consume '.'

    var pow = 1
    var num = self._input._buffer.offset(self._cursor).load().asInt() - 48
    self._advance()
    while self._input[self._cursor].isDigit() {
      num *= 10
      num += self._input._buffer.offset(self._cursor).load().asInt() - 48
      self._advance()
      pow += 1
    }

    if self._input[self._cursor] == "." && self._input[self._cursor + 1].isDigit() {
      val char = self._input[self._cursor]
      return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(char)))
    }

    val float = wholeNumber + (num / 10 ** pow)
    Result.Ok(Token(position: startPos, kind: TokenKind.Float(float)))
  }

  func _tokenizeString(self, startPos: Position): Result<Token, LexerError> {
    self._advance() // consume '"'

    var chars: String[] = []
    val start = self._cursor
    var closed = false
    var seenEscape = false
    while self._cursor < self._input.length {
      val ch = self._input[self._cursor]
      if ch == "\n" {
        return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnterminatedString(startPos)))
      } else if ch == "\\" {
        val startCursor = self._cursor
        val pos = self._curPos()
        self._advance() // consume '\'

        val ch = self._input[self._cursor]
        val escapedCh = match ch {
          "n" => "\n"
          "\\" => "\\",
          "r" => "\r",
          "t" => "\t",
          "\'" => "\'",
          "\"" => "\"",
          "$" => "$",
          "u" => match self._parseUnicodeEscape(pos) {
            Result.Ok(c) => c
            Result.Err(e) => return Result.Err(e)
          }
          _ => return Result.Err(LexerError(position: pos, kind: LexerErrorKind.UnsupportedEscapeSequence("\\$ch", false)))
        }

        if !seenEscape {
          seenEscape = true
          chars = self._input[start:startCursor].split()
        }
        chars.push(escapedCh)
      // } else if ch == "$" && self._input[self._cursor + 1] == "{" || self._input[self._cursor + 1].isAlpha() {
      //   val str = if seenEscape chars.join() else self._input[start:self._cursor]
      //   return self._tokenizeStringInterpolation(startPos: startPos, firstChunk: str)
      } else if ch == "\"" {
        closed = true
        break
      } else {
        if seenEscape {
         chars.push(ch)
        }
      }

      self._advance()
    }

    if !closed {
      return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnterminatedString(startPos)))
    }

    val str = if seenEscape chars.join() else self._input[start:self._cursor]

    self._advance() // consume closing '"'

    Result.Ok(Token(position: startPos, kind: TokenKind.String(str)))
  }

  func _parseUnicodeEscape(self, startPos: Position): Result<String, LexerError> {
    self._advance() // consume 'u'

    var value = 0
    for i in range(0, 4) {
      if self._cursor + i >= self._input.length {
        val escSeq = "\\u${self._input[self._cursor:self._cursor + i]}"
        return Result.Err(LexerError(position: startPos, kind: LexerErrorKind.UnsupportedEscapeSequence(escSeq, true)))
      }
      val ch = self._input._buffer.offset(self._cursor + i).load().asInt()
      val v = if valueIfValidHexDigit(ch) |v| v else {
        val escSeq = "\\u${self._input[self._cursor:self._cursor + i]}"
        return Result.Err(LexerError(position: startPos, kind: LexerErrorKind.UnsupportedEscapeSequence(escSeq, true)))
      }
      value = (value << 4) + v
    }
    self._advance()
    self._advance()
    self._advance()

    // TODO: Clean up this unicode->utf-8 conversion and abstract it away into some stdlib method once Chars exist?
    val str = if !(value.isBetween(0, 0xD7FF, true) || value.isBetween(0xE000, 0x10FFFF, true)) {
      "�"
    } else if value.isBetween(0, 0x007F, true) {
      val s = String.withLength(1)
      s._buffer.offset(0).store(Byte.fromInt(value))
      s
    } else if value.isBetween(0x0080, 0x07FF, true) {
      val s = String.withLength(2)
      val b1 = 0b11000000 || (value && 0b11111000000)
      val b2 = 0b10000000 || (value && 0b00000111111)
      s._buffer.offset(0).store(Byte.fromInt(b1))
      s._buffer.offset(1).store(Byte.fromInt(b2))
      s
    } else if value.isBetween(0x0800, 0xFFFF, true) {
      val s = String.withLength(3)
      val b1 = 0b11100000 || ((value && 0b1111000000000000) >> 12)
      val b2 = 0b10000000 || ((value && 0b0000111111000000) >> 6)
      val b3 = 0b10000000 || (value && 0b0000000000111111)
      s._buffer.offset(0).store(Byte.fromInt(b1))
      s._buffer.offset(1).store(Byte.fromInt(b2))
      s._buffer.offset(2).store(Byte.fromInt(b3))
      s
    } else if value.isBetween(0x10000, 0x10FFFF, true) {
      val s = String.withLength(4)
      val b1 = 0b11110000 || (value && 0b111000000000000000000)
      val b2 = 0b10000000 || (value && 0b000111111000000000000)
      val b3 = 0b10000000 || (value && 0b000000000111111000000)
      val b4 = 0b10000000 || (value && 0b000000000000000111111)
      s._buffer.offset(0).store(Byte.fromInt(b1))
      s._buffer.offset(1).store(Byte.fromInt(b2))
      s._buffer.offset(2).store(Byte.fromInt(b3))
      s._buffer.offset(3).store(Byte.fromInt(b4))
      s
    } else {
      "�"
    }

    Result.Ok(str)
  }

  func _tokenizeStringInterpolation(self, startPos: Position, firstChunk: String): Result<Token, LexerError> {
    // TODO
    Result.Ok(Token(position: startPos, kind: TokenKind.StringInterpolation([Token(position: startPos, kind: TokenKind.String(firstChunk))])))
  }

  func _tokenizeIdentifier(self, startPos: Position): Token {
    val identStart = self._cursor
    var ch = self._input[self._cursor]

    while ch.isAlphanumeric() || ch == "_" {
      self._advance()
      ch = self._input[self._cursor]
    }

    val ident = self._input[identStart:self._cursor]
    val tokenKind = match ident {
      "true" => TokenKind.Bool(true)
      "false" => TokenKind.Bool(false)
      "if" => TokenKind.If
      "else" => TokenKind.Else
      "val" => TokenKind.Val
      "var" => TokenKind.Var
      "func" => TokenKind.Func
      "self" => TokenKind.Self
      "while" => TokenKind.While
      "break" => TokenKind.Break
      "continue" => TokenKind.Continue
      "for" => TokenKind.For
      "in" => TokenKind.In
      "match" => TokenKind.Match
      "type" => TokenKind.Type
      "enum" => TokenKind.Enum
      "return" => TokenKind.Return
      "readonly" => TokenKind.Readonly
      "import" => TokenKind.Import
      "export" => TokenKind.Export
      "from" => TokenKind.From
      "as" => TokenKind.As
      "try" => TokenKind.Try
      "None" => TokenKind.None_
      _ => TokenKind.Ident(ident)
    }
    Token(position: startPos, kind: tokenKind)
  }

  func _tokenizeSymbol(self, startPos: Position, sawPreceedingNewline: Bool): Result<Token, LexerError> {
    val ch = self._input[self._cursor]

    val tokenKind = match ch {
      "+" => self._multiCharToken(TokenKind.Plus, [("=", TokenKind.PlusEq)])
      "-" => self._multiCharToken(TokenKind.Minus, [("=", TokenKind.MinusEq)])
      "*" => self._multiCharToken(TokenKind.Star, [("=", TokenKind.StarEq), ("*", TokenKind.StarStar)])
      "/" => self._multiCharToken(TokenKind.Slash, [("=", TokenKind.SlashEq)])
      "%" => self._multiCharToken(TokenKind.Percent, [("=", TokenKind.PercentEq)])
      "<" => self._multiCharToken(TokenKind.LT, [("=", TokenKind.LTE)])
      ">" => self._multiCharToken(TokenKind.GT, [("=", TokenKind.GTE)])
      "!" => self._multiCharToken(TokenKind.Bang, [("=", TokenKind.Neq)])
      "=" => self._multiCharToken(TokenKind.Eq, [("=", TokenKind.EqEq), (">", TokenKind.Arrow)])
      "." => TokenKind.Dot
      "^" => TokenKind.Caret
      "(" => TokenKind.LParen(preceedingNewline: sawPreceedingNewline)
      ")" => TokenKind.RParen
      "[" => TokenKind.LBrack(preceedingNewline: sawPreceedingNewline)
      "]" => TokenKind.RBrack
      "{" => TokenKind.LBrace
      "}" => TokenKind.RBrace
      "&" => {
        self._advance() // consume '&'
        if self._cursor >= self._input.length {
          return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof))
        } else if self._input[self._cursor] != "&" {
          val ch = self._input[self._cursor]
          return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(ch)))
        }
        self._advance() // consume second '&'

        if self._input[self._cursor] == "=" {
          self._advance() // consume '='
          TokenKind.AndEq
        } else {
          TokenKind.And
        }
      }
      "|" => self._multiCharToken(TokenKind.Pipe, [("|=", TokenKind.OrEq), ("|", TokenKind.Or)])
      "," => TokenKind.Comma
      ":" => TokenKind.Colon
      "?" => self._multiCharToken(TokenKind.Question, [(":=", TokenKind.ElvisEq), (":", TokenKind.Elvis), (".", TokenKind.QuestionDot)])
      "#" => {
        self._advance() // consume '#'
        if self._cursor >= self._input.length {
          return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedEof))
        } else if self._input[self._cursor] != "{" {
          val ch = self._input[self._cursor]
          return Result.Err(LexerError(position: self._curPos(), kind: LexerErrorKind.UnexpectedChar(ch)))
        }

        TokenKind.HashBrace
      }
      "@" => TokenKind.At
      _ => return Result.Err(LexerError(position: startPos, kind: LexerErrorKind.UnexpectedChar(ch)))
    }

    self._advance()

    Result.Ok(Token(position: startPos, kind: tokenKind))
  }
}
